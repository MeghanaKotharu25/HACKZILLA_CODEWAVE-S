#!/usr/bin/env python3
"""
Test script to verify model loading functionality before running Streamlit app.
"""

import os
import pickle
import torch
import torch.nn as nn
from huggingface_hub import hf_hub_download
from sklearn.ensemble import IsolationForest

# Config
HF_AIS_REPO = "MeghanaK25/ais-isolation-forest"
HF_AIS_FILENAME = "isolationforest_model.pkl"
HF_SAR_REPO = "MeghanaK25/sar-oil-slick-detection"
HF_SAR_FILENAME = "oil_slick_resnet_subset.pth"

LOCAL_AIS_MODEL = "/Users/lakshmikotaru/Documents/ais_isolation_forest/isolationforest_model.pkl"
LOCAL_SAR_WEIGHTS = "/Users/lakshmikotaru/Documents/sar_oil_slick_detection/hf_deployment/oil_slick_resnet_subset.pth"

class ResNetOilSlickModel(nn.Module):
    """ResNet-based model for oil slick detection in SAR images - compatible with saved weights"""
    
    def __init__(self, num_classes: int = 2):
        super(ResNetOilSlickModel, self).__init__()
        
        # Load pre-trained ResNet backbone - use the same structure as the saved model
        import torchvision.models as models
        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        
        # Modify first conv layer for single channel (SAR grayscale)
        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        
        # The saved model seems to have the ResNet with fc layer intact
        # So we keep it as is and just change the output size
        in_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(in_features, num_classes)  # Direct classification
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Use standard ResNet forward pass
        batch_size = x.shape[0]
        features = self.resnet(x)  # Output shape: (batch_size, num_classes)
        
        # Convert to segmentation format by upsampling the classification to match expected output
        # This is a simple approach - broadcast the class probabilities to spatial dimensions
        output = features.unsqueeze(-1).unsqueeze(-1)  # (batch_size, num_classes, 1, 1)
        output = torch.nn.functional.interpolate(output, size=(224, 224), mode='nearest')  # (batch_size, num_classes, 224, 224)
        
        return output

def test_ais_model_loading():
    """Test AIS model loading from HuggingFace with local fallback."""
    print("Testing AIS model loading...")
    
    try:
        print("  Trying Hugging Face...")
        model_path = hf_hub_download(repo_id=HF_AIS_REPO, filename=HF_AIS_FILENAME, repo_type="model")
        with open(model_path, "rb") as f:
            model = pickle.load(f)
        print("  ‚úÖ Successfully loaded AIS model from Hugging Face")
        print(f"     Model type: {type(model)}")
        return model
    except Exception as e:
        print(f"  ‚ùå Hugging Face failed: {e}")
        print("  Trying local fallback...")
        try:
            with open(LOCAL_AIS_MODEL, "rb") as f:
                model = pickle.load(f)
            print("  ‚úÖ Successfully loaded AIS model from local fallback")
            print(f"     Model type: {type(model)}")
            return model
        except Exception as e2:
            print(f"  ‚ùå Local fallback also failed: {e2}")
            return None

def test_sar_model_loading():
    """Test SAR model loading from HuggingFace with local fallback."""
    print("Testing SAR model loading...")
    device = torch.device("cpu")  # Use CPU for testing
    
    weights_path = None
    try:
        print("  Trying Hugging Face...")
        weights_path = hf_hub_download(repo_id=HF_SAR_REPO, filename=HF_SAR_FILENAME, repo_type="model")
        print("  ‚úÖ Successfully downloaded SAR weights from Hugging Face")
    except Exception as e:
        print(f"  ‚ùå Hugging Face failed: {e}")
        print("  Trying local fallback...")
        if LOCAL_SAR_WEIGHTS and os.path.exists(LOCAL_SAR_WEIGHTS):
            weights_path = LOCAL_SAR_WEIGHTS
            print("  ‚úÖ Using local SAR weights fallback")
        else:
            print("  ‚ùå Local SAR weights not found")
            return None
    
    if weights_path:
        try:
            # Create model
            model = ResNetOilSlickModel(num_classes=2)
            model.to(device)
            model.eval()
            
            # Load weights with custom handling for shape mismatches
            state = torch.load(weights_path, map_location=device)
            
            # Custom loading to handle conv1 layer shape mismatch (3->1 channels)
            model_dict = model.state_dict()
            compatible_state = {}
            
            for key, value in state.items():
                if key == 'resnet.conv1.weight':
                    # Handle conv1 layer: convert from 3 channels to 1 channel by averaging
                    if value.shape[1] == 3 and key in model_dict and model_dict[key].shape[1] == 1:
                        # Average the 3 input channels to create 1 channel
                        compatible_state[key] = value.mean(dim=1, keepdim=True)
                        print(f"  ‚ÑπÔ∏è Converted {key} from {value.shape} to {compatible_state[key].shape}")
                    else:
                        compatible_state[key] = value
                else:
                    if key in model_dict and value.shape == model_dict[key].shape:
                        compatible_state[key] = value
            
            # Load the compatible weights
            missing_keys, unexpected_keys = model.load_state_dict(compatible_state, strict=False)
            
            # Report loading results
            print(f"  ‚ÑπÔ∏è Loaded {len(compatible_state)} compatible weights from saved model")
            if missing_keys:
                print(f"  ‚ö†Ô∏è Missing keys: {len(missing_keys)} (will use pretrained values)")
            
            print("  ‚úÖ Successfully loaded SAR model weights")
            print(f"     Model type: {type(model)}")
            print(f"     Number of parameters: {sum(p.numel() for p in model.parameters()):,}")
            return model
        except Exception as e:
            print(f"  ‚ùå Failed to load weights: {e}")
            return None
    else:
        print("  ‚ùå No weights available")
        return None

def test_demo_data():
    """Test demo data availability."""
    print("Testing demo data...")
    
    # Check Red Sea demo image
    demo_path = "/Users/lakshmikotaru/Documents/sar_oil_slick_detection/red_sea_demo.png"
    if os.path.exists(demo_path):
        print("  ‚úÖ Red Sea demo image available")
    else:
        print("  ‚ùå Red Sea demo image not found")
    
    # Check AIS demo CSV
    csv_path = "/Users/lakshmikotaru/Documents/sar_oil_slick_detection/demo_ais_data.csv"
    if os.path.exists(csv_path):
        print("  ‚úÖ AIS demo CSV available")
    else:
        print("  ‚ùå AIS demo CSV not found")

def main():
    print("üß™ Testing model loading and demo data...")
    print("=" * 50)
    
    # Test AIS model
    ais_model = test_ais_model_loading()
    print()
    
    # Test SAR model  
    sar_model = test_sar_model_loading()
    print()
    
    # Test demo data
    test_demo_data()
    print()
    
    # Summary
    print("=" * 50)
    if ais_model is not None and sar_model is not None:
        print("üéâ All models loaded successfully! Ready to run Streamlit app.")
    else:
        print("‚ö†Ô∏è  Some models failed to load. Check the errors above.")
    
    print("\nTo run the Streamlit app:")
    print("  streamlit run streamlit_app.py")

if __name__ == "__main__":
    main()
